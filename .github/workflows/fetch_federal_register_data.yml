name: Fetch Federal Register Data (Input Driven)

on:
  workflow_dispatch:
    inputs:
      subcommand:
  schedule:
    - cron: '0 6 * * *'
        description: "fetch_fr.py subcommand (e.g., documents-search, agencies, issues)"
        required: true
        default: "documents-search"
      term:
        description: "Search term (for documents-search, public-inspection-search)"
        required: false
      pub_date_year:
        description: "Publication year (YYYY for documents-search)"
        required: false
      pub_date_gte:
        description: "Publication date greater than or equal (YYYY-MM-DD for documents-search)"
        required: false
      pub_date_lte:
        description: "Publication date less than or equal (YYYY-MM-DD for documents-search)"
        required: false
      pub_date_is:
        description: "Exact publication date (YYYY-MM-DD for documents-search or issues)"
        required: false
      agency_slug:
        description: "Agency slug (for documents-search, agency-single)"
        required: false
      doc_type:
        description: "Document type (RULE, PRORULE, NOTICE, PRESDOCU for documents-search)"
        required: false
      doc_number:
        description: "Document number (for documents-single, public-inspection-single)"
        required: false
      per_page:
        description: "Documents per page (max 1000)"
        required: false
        default: "20"
      page:
        description: "Page number of results"
        required: false
      order:
        description: "Order of results (relevance, newest, oldest, executive_order_number)"
        required: false
      query_terms:
        description: 'Comma-separated terms'
        required: false
        default: 'education'
      # Add other inputs as needed for different subcommands

jobs:
  fetch_data:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Setup Python
      uses: actions/setup-python@v4 # Keep newer version
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests # Ensure requests is installed for fetch_fr.py

    - name: Build fetch_fr.py arguments
      id: fr_args
      run: |
        args=""
        # Term will be handled in the loop, so it's removed from here.
        if [ -n "${{ github.event.inputs.pub_date_year }}" ]; then args="$args --pub_date_year \"${{ github.event.inputs.pub_date_year }}\""; fi
        if [ -n "${{ github.event.inputs.pub_date_gte }}" ]; then args="$args --pub_date_gte \"${{ github.event.inputs.pub_date_gte }}\""; fi
        if [ -n "${{ github.event.inputs.pub_date_lte }}" ]; then args="$args --pub_date_lte \"${{ github.event.inputs.pub_date_lte }}\""; fi
        if [ -n "${{ github.event.inputs.pub_date_is }}" ]; then args="$args --pub_date_is \"${{ github.event.inputs.pub_date_is }}\""; fi
        if [ -n "${{ github.event.inputs.agency_slug }}" ]; then args="$args --agency_slug \"${{ github.event.inputs.agency_slug }}\""; fi # Note: fetch_fr.py handles multiple via action=append
        if [ -n "${{ github.event.inputs.doc_type }}" ]; then args="$args --doc_type \"${{ github.event.inputs.doc_type }}\""; fi # Note: fetch_fr.py handles multiple via action=append
        if [ -n "${{ github.event.inputs.doc_number }}" ]; then args="$args --doc_number \"${{ github.event.inputs.doc_number }}\""; fi
        if [ -n "${{ github.event.inputs.per_page }}" ]; then args="$args --per_page \"${{ github.event.inputs.per_page }}\""; fi
        if [ -n "${{ github.event.inputs.page }}" ]; then args="$args --page \"${{ github.event.inputs.page }}\""; fi
        if [ -n "${{ github.event.inputs.order }}" ]; then args="$args --order \"${{ github.event.inputs.order }}\""; fi
        # Add similar lines for other specific args like --facet, --publication_date (for issues)
        # For simplicity, this example focuses on common documents-search args.
        # A more robust solution might involve passing all inputs directly if script can ignore unused ones,
        # or having distinct workflows per subcommand for clarity.
        echo "script_args=$args" >> $GITHUB_OUTPUT

    - name: Determine Query Terms
      id: determine_terms
      run: |
        TERMS_SOURCE_FILE="config/federal_register_terms.txt"
        FINAL_TERMS_STRING=""
        if [[ -f "$TERMS_SOURCE_FILE" ]]; then
          echo "Reading terms from $TERMS_SOURCE_FILE"
          # Read file, filter empty/whitespace lines, then join with comma
          TEMP_TERMS_STRING=$(grep -v '^[[:space:]]*$' "$TERMS_SOURCE_FILE" | paste -sd "," -)
          # Check if TEMP_TERMS_STRING is non-empty after processing file
          if [[ -n "$TEMP_TERMS_STRING" ]]; then
            FINAL_TERMS_STRING="$TEMP_TERMS_STRING"
            echo "Using terms from file: $FINAL_TERMS_STRING"
          else
            echo "Term file $TERMS_SOURCE_FILE is empty or contains only whitespace. Falling back to workflow input."
            FINAL_TERMS_STRING="${{ github.event.inputs.query_terms }}"
            echo "Using terms from workflow input: $FINAL_TERMS_STRING"
          fi
        else
          echo "$TERMS_SOURCE_FILE does not exist. Using terms from workflow input."
          FINAL_TERMS_STRING="${{ github.event.inputs.query_terms }}"
          echo "Using terms from workflow input: $FINAL_TERMS_STRING"
        fi
        # Clean the final string: remove leading/trailing whitespace and commas
        CLEANED_TERMS_STRING=$(echo "$FINAL_TERMS_STRING" | sed 's/^[[:space:]]*[,[:space:]]*//;s/[,[:space:]]*[[:space:]]*$//')
        echo "resolved_query_terms=$CLEANED_TERMS_STRING" >> $GITHUB_OUTPUT

    - name: Fetch Data from Federal Register using fetch_fr.py
      run: |
        RAW_TERMS_STRING="${{ steps.determine_terms.outputs.resolved_query_terms }}"
        if [[ -z "$RAW_TERMS_STRING" ]]; then
          echo "No terms to process after checking config file and workflow input."
          exit 0 # Exit gracefully if no terms are found
        fi

        IFS=',' read -ra TERMS_ARRAY <<< "$RAW_TERMS_STRING"
        for term_item in "${TERMS_ARRAY[@]}"; do
          # Trim whitespace from term_item (important if there are spaces around commas)
          trimmed_term=$(echo "$term_item" | xargs) # xargs trims leading/trailing whitespace
          if [ -n "$trimmed_term" ]; then
            echo "Processing term: '$trimmed_term'"
            # Construct final arguments for the script, adding the current term
            final_args="--term \"$trimmed_term\" ${{ steps.fr_args.outputs.script_args }}"
            python scripts/fetch_fr.py ${{ github.event.inputs.subcommand }} $final_args
          else
            echo "Skipping empty term after trimming."
          fi
        done

    - name: Commit and Push Changes
      run: |
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        # Check if there are any new or modified JSON files in the data directory
        if ! git diff --quiet --exit-code data/*.json && git diff --cached --quiet --exit-code data/*.json; then
          git add data/*.json
          git commit -m "Auto-update Federal Register data via workflow"
          git push
        else
          echo "No changes to JSON files in data/ to commit."
        fi